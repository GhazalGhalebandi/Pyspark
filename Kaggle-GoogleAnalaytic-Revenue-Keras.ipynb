{"cells":[{"cell_type":"markdown","source":["- analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. \n- we're predicting the natural log of the total revenue per unique user"],"metadata":{}},{"cell_type":"code","source":["from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import RandomForestRegressor\nfrom pyspark.ml.feature import VectorIndexer\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\nimport pandas as pd\nimport numpy as np\nimport json"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# File location and type\nfile_location = \"/FileStore/tables/train.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"false\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\ntrain = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .option('quote', '\"') \\\n  .option('escape', '\"') \\\n  .load(file_location)\n\ndisplay(train)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# get the length of all json columns \ndef udf_calculate_json_len(col):\n  j_col = json.loads(col)\n  return len(j_col)\nudf_calculate_json_len = udf(udf_calculate_json_len, IntegerType())\n\n\n\ndisplay(\n  train.select('device', udf_calculate_json_len('device').alias('len')).sort(desc('len'))\n)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["\ngeoNetworkSchema = StructType(\n  [\n    StructField(\"continent\", StringType()),\n    StructField(\"subContinent\", StringType()),\n    StructField(\"country\", StringType()),\n    StructField(\"region\", StringType()),\n    StructField(\"metro\", StringType()),\n    StructField(\"city\", StringType()),\n    StructField(\"cityId\", StringType()),\n    StructField(\"networkDomain\", StringType()),\n    StructField(\"latitude\", StringType()),\n    StructField(\"longitude\", StringType()),\n    StructField(\"networkLocation\", StringType()),\n  ]\n)\n\n\ndeviceSchema = StructType(\n  [\n    StructField(\"browser\", StringType()),\n    StructField(\"browserVersion\", StringType()),\n    StructField(\"browserSize\", StringType()),\n    StructField(\"operatingSystem\", StringType()),\n    StructField(\"operatingSystemVersion\", StringType()),\n    StructField(\"isMobile\", StringType()),\n    StructField(\"mobileDeviceBranding\", StringType()),\n    StructField(\"mobileDeviceModel\", StringType()),\n    StructField(\"mobileInputSelector\", StringType()),\n    StructField(\"mobileDeviceInfo\", StringType()),\n    StructField(\"mobileDeviceMarketingName\", StringType()),\n    StructField(\"flashVersion\", StringType()),\n    StructField(\"language\", StringType()),\n    StructField(\"screenColors\", StringType()),\n    StructField(\"screenResolution\", StringType()),\n    StructField(\"deviceCategory\", StringType()),\n  ]\n)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["totals_schema = StructType([ StructField(\"visits\", StringType(), True),\n                     StructField(\"hits\", StringType(), True),\n                     StructField(\"pageviews\", StringType(), True),\n                     StructField(\"bounces\", StringType(), True),\n                     StructField(\"transactionRevenue\", StringType(), True),\n                     StructField(\"newVisits\", StringType(), True)\n                        ])\n\n\ntrafficSource_schema = StructType(\n  [\n    StructField(\"campaign\", StringType(), True),\n    StructField(\"source\", StringType(), True),\n    StructField(\"medium\", StringType(), True),\n    StructField(\"keyword\", StringType(), True),\n    StructField(\"adContent\", StringType(), True),\n    StructField(\"adwordsClickInfo\", StructType(\n      [\n        StructField('page', StringType() , True),\n        StructField('slot', StringType() , True),\n        StructField('criteriaParameters', StringType() , True),\n        StructField('gclId', StringType() , True),\n        StructField('adNetworkType', StringType() , True),\n        StructField('isVideoAd', StringType() , True),\n      ]\n    ), True),\n    StructField('isTrueDirect', StringType() , True)\n  ]\n)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# train2 = train.withColumn(\"_totals\", from_json(train[\"totals\"], totals_schema))\ntrain = train.withColumn(\"_trafficSource\", from_json(train[\"trafficSource\"], trafficSource_schema)\n).withColumn(\"_totals\", from_json(train[\"totals\"], totals_schema\n)).withColumn(\"_device\", from_json(train[\"device\"], deviceSchema\n)).withColumn(\"_geoNetwork\", from_json(train[\"geoNetwork\"], geoNetworkSchema\n))\n                        \ndisplay(train)                     "],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["train_exploded = train.select('fullVisitorId','channelGrouping', \n                         'date', \n                         col('_device.*'),\n                         'fullVisitorId',\n                         col('_geoNetwork.*'),\n                         'sessionId',\n                         'socialEngagementType',\n                         col('_totals.*'),\n                         col('_trafficSource.*'),\n                         'visitId',\n                         'visitNumber',\n                         'visitStartTime'\n                             ) \n\ndisplay(train_exploded)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["print(\"# of row\" , train_exploded.count())\nprint(\"# of cols\" , len(train_exploded.columns))"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["selected_features = ['fullVisitorId','bounces', 'visits', 'newVisits', 'hits', 'pageviews' , 'visitNumber', 'transactionRevenue']\n\ntrain_selected = train_exploded.select(selected_features)\n  \n#  'channelGrouping',\n#  'date',\n#  'fullVisitorId',\n#  'sessionId',\n#  'visitId',\n#  'visitNumber',\n#  'visitStartTime',\n#  'browser',\n#  'deviceCategory',\n#  'isMobile',\n#  'operatingSystem',\n#  'city',\n#  'continent',\n#  'country',\n#  'metro',\n#  'networkDomain',\n#  'region',\n#  'subContinent',\n#  'bounces',\n#  'hits',\n#  'visits',\n#  'newVisits',\n#  'pageviews',\n#  'transactionRevenue',\n#  'adContent',\n#  'campaign',\n#  'isTrueDirect',\n#  'keyword',\n#  'medium',\n#  'source')\n\nprint(\"# of row\" , train_selected.count())\nprint(\"# of cols\" , len(train_selected.columns))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# train_fillna_revenue = train_selected.select(\"transactionRevenue\").fillna(0.0)\n# df.fillna( { 'a':0, 'b':0 } )\n\ntrain_fillna = train_selected.fillna( { \"transactionRevenue\":0 , \n                             \"visitNumber\" : 0 , \n                             \"bounces\" : 0 , \n                             \"visits\" : 0 , \n                             \"newVisits\" : 0 , \n                             \"hits\" : 0 , \n                             \"pageviews\" : 0\n                            } )\n\ntrain_fillna.filter(col(\"transactionRevenue\").isNull()).count()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["train_convert_to_double = train_fillna.withColumn(\"visitNumber_flt\", col(\"visitNumber\").cast(\"double\")\n).withColumn(\"bounces_flt\", col(\"bounces\").cast(\"double\")\n).withColumn(\"visits_flt\", col(\"visits\").cast(\"double\")\n).withColumn(\"newVisits_flt\", col(\"newVisits\").cast(\"double\")\n).withColumn(\"hits_flt\", col(\"hits\").cast(\"double\")\n).withColumn(\"pageviews_flt\", col(\"pageviews\").cast(\"double\")\n).withColumn(\"transactionRevenue_flt\", col(\"transactionRevenue\").cast(\"double\"))\n\ntrain_convert_to_double.printSchema()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["train_groupby = train_convert_to_double.groupby('fullVisitorId').sum()\n\ntrain_groupby_renamed = train_groupby.withColumnRenamed(\"sum(visitNumber_flt)\", \"visitNumber_flt\"\n).withColumnRenamed(\"sum(bounces_flt)\", \"bounces_flt\"\n).withColumnRenamed(\"sum(bounces_flt)\", \"bounces_flt\"\n).withColumnRenamed(\"sum(visits_flt)\", \"visits_flt\"\n).withColumnRenamed(\"sum(newVisits_flt)\", \"newVisits_flt\"                   \n).withColumnRenamed(\"sum(hits_flt)\", \"hits_flt\"                      \n).withColumnRenamed(\"sum(pageviews_flt)\", \"pageviews_flt\"                     \n).withColumnRenamed(\"sum(transactionRevenue_flt)\", \"transactionRevenue_flt\")                       \n                    \ndisplay(train_groupby_renamed)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# categorical_feature_encoded = ['channelGroupingIndex', 'browserIndex', 'deviceCategoryIndex', 'isMobileIndex' , 'countryIndex' , 'mediumIndex', 'sourceIndex']\n# categorical_feature_encoded = ['channelGrouping', 'browser', 'deviceCategory', 'isMobile' , 'country' , 'medium', 'source']\n\nnumerical_features = ['bounces_flt', 'visits_flt', 'newVisits_flt', 'hits_flt', 'pageviews_flt' , 'visitNumber_flt']\n\n# feature_columns = categorical_feature_encoded + numerical_features \nfeature_columns = numerical_features\n\nlabel_column = ['transactionRevenue_flt']\n"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["train_ = train_groupby_renamed.select(feature_columns + label_column)\ndisplay(train_)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["describe_train_df = train_.describe()\n\ndisplay(describe_train_df)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["# Normalizing features \n  - x = value \n  - dl = min of attribute \n  - dh = max of attribute \n  - nl = min of expected range \n  - nh = max of expected range"],"metadata":{}},{"cell_type":"code","source":["# call function\n#normalize columns\ndef normalizing_column(c , dL, dH):\n  nL = 0\n  nH = 1\n  numi = (float(c) - dL) * (nH-nL)\n  denom = dH - dL\n  div = float(numi) / float(denom)\n  normalized = float(div + nL)\n  return normalized\n\nnormalizing_column_udf = udf(normalizing_column, DoubleType())\n\n\n# names = train_.schema.names\nnames = ['hits_flt',\n 'pageviews_flt',\n 'visitNumber_flt',\n 'bounces_flt',\n 'visits_flt',\n 'newVisits_flt',\n        ]\nfor colname in names:\n  dL = float(describe_train_df.collect()[3][colname])\n  dH = float(describe_train_df.collect()[4][colname])\n  train_ = train_.withColumn('normalized_' + str(colname), \n                           normalizing_column_udf(colname, lit(dL) , lit(dH))\n                          )    "],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["display(train_.describe())"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["selected_train_ = train_.select('transactionRevenue_flt', 'normalized_hits_flt', 'normalized_pageviews_flt', 'normalized_visitNumber_flt', 'normalized_bounces_flt', 'normalized_visits_flt', 'normalized_newVisits_flt')\ndisplay(selected_train_)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["train_pd = selected_train_.toPandas()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["train_pd.dtypes"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["train_x = train_pd.drop(['transactionRevenue_flt'], axis = 1)\nn_cols = train_x.shape[1]\ntrain_x.head()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["train_y2 = train_pd.transactionRevenue_flt\ntrain_y2.head()"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["train_y2_log = np.log(train_y2)\ntrain_y2_log.head()"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["train_y2 = train_y2_log.replace('-inf', 0.0)\ntrain_y2.describe()\n# train_y2.describe()"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["# define\nmodel = Sequential()\n\n#add model layers\nmodel.add(Dense(7, activation='relu', input_shape=(n_cols,)))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dense(1))\n\nmodel.compile(loss='mean_squared_error', optimizer='adam')\n\n#7 input model - mse ---- loss = 5.9617 , after new log --> loss =  3.1654"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["# from keras.callbacks import EarlyStopping\n#set early stopping monitor so the model stops training when it won't improve anymore\n# early_stopping_monitor = EarlyStopping(patience=3)\n#train model\nmodel.fit(train_x, train_y2, epochs=10)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["# define\nmodel2 = Sequential()\n\n#add model layers\nmodel2.add(Dense(200, activation='relu', input_shape=(n_cols,)))\nmodel2.add(Dense(200, activation='relu'))\nmodel2.add(Dense(200, activation='relu'))\nmodel2.add(Dense(1))\n\nmodel2.compile(loss='mean_squared_error', optimizer='adam')\nmodel2.fit(train_x, train_y2, epochs=10)\n\n#200 input model - mse ---- loss = 6.1056 , after new log --> loss = 3.1392"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# define\nmodel3 = Sequential()\n\n#add model layers\nmodel3.add(Dense(7, activation='relu', input_shape=(n_cols,)))\nmodel3.add(Dense(7, activation='relu'))\nmodel3.add(Dense(1))\n\n\n\n#create a custome loss and compile model using mse as a measure of model performance\nfrom keras import backend as K\ndef root_mean_squared_error(y_true, y_pred):\n        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n\nmodel3.compile(optimizer = \"adam\", loss = root_mean_squared_error)\n\n\nfrom keras.callbacks import EarlyStopping\n#set early stopping monitor so the model stops training when it won't improve anymore\n# early_stopping_monitor = EarlyStopping(patience=3)\n#train model\nmodel3.fit(train_x, train_y2, epochs=5)\n\n#loss: 0.2492"],"metadata":{},"outputs":[],"execution_count":31}],"metadata":{"name":"GoogleAnalaytic-Revenue-final","notebookId":1408586},"nbformat":4,"nbformat_minor":0}
