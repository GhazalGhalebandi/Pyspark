{"cells":[{"cell_type":"code","source":["%run development/libraries/placements-proxy"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["def remove_html(anystring):\n  if anystring:\n    parser=HTMLParser()\n    anystring = parser.unescape(anystring)\n    anystring=re.sub(\"<.*?>\",\" \",anystring)\n    #anystring = re.sub(\"&\\w+;\",\" \",anystring)\n    anystring=re.sub(\"\\xa0\",\" \",anystring)\n  return anystring\n\nremove_html = udf(remove_html , StringType())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["country = 'hk'\ntrain = spark.read.parquet(\"s3a://exploratory/\"+country+\"/data/train_v4\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["def process_profile_text(JsGlobal_JobSeekerWorkExperience_Position, JsGlobal_JobSeekerWorkExperience_JobDuties , JsGlobal_JobSeekerSkill_Skill):\n  text = ''\n  if JsGlobal_JobSeekerWorkExperience_Position and JsGlobal_JobSeekerWorkExperience_JobDuties: \n    if len(JsGlobal_JobSeekerWorkExperience_Position) == len(JsGlobal_JobSeekerWorkExperience_JobDuties):\n      for i in range(len(JsGlobal_JobSeekerWorkExperience_Position)):\n        text += JsGlobal_JobSeekerWorkExperience_Position[i] + JsGlobal_JobSeekerWorkExperience_JobDuties[i] + ' '\n    else:\n      text = ' '\n  if JsGlobal_JobSeekerSkill_Skill:\n    text += \",\" . join(JsGlobal_JobSeekerSkill_Skill)     \n  return text\n\nprocess_profile_text = udf(process_profile_text, StringType())\n\nconcat_list = udf(lambda x: \", \" . join(x) if x and len(x)>0 else '')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["#candidate profile\nprofile_text = train.select(\n  'JobSeekerId',\n  'JsGlobal_JobSeekerWorkExperience_Position', \n  'JsGlobal_JobSeekerWorkExperience_JobDuties', \n  'JsGlobal_JobSeekerSkill_Skill'\n).dropDuplicates().select(\n  process_profile_text('JsGlobal_JobSeekerWorkExperience_Position' , 'JsGlobal_JobSeekerWorkExperience_JobDuties' , 'JsGlobal_JobSeekerSkill_Skill').alias('text')\n)\n\n#candidate online resume\nresume_text = train.select(\n  'ResumeId',\n  'JsResume_WorkExperience_Position', \n  'JsResume_SkillsContent', \n).dropDuplicates().select(\n  concat(\n    concat_list('JsResume_WorkExperience_Position'),\n    remove_html('JsResume_SkillsContent')\n  ).alias('text')\n).dropna(subset=['text'])\n\n#jobAds\njobads_text = train.select(  \n  'JobAdId',\n  'JobAd_JobTitle',\n  'JobAd_JobDescriptionRequirement'\n).dropDuplicates().select(\n  concat(\n    'JobAd_JobTitle',\n    remove_html('JobAd_JobDescriptionRequirement')\n  ).alias('text')\n)\n\n#create a corpus\ntext_df = profile_text.union(resume_text).union(jobads_text)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["print(profile_text.count())\nprint(resume_text.count())\nprint(jobads_text.count())\nprint(text_df.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">50149\n1495\n57833\n109477\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF, Tokenizer\nfrom pyspark.ml.feature import StopWordsRemover\nfrom pyspark.ml import Pipeline\n\n\nregex_tokenizer = RegexTokenizer(inputCol='text', outputCol=\"tokenized_text\" , pattern=\"[\\s,(),\\W+]\", minTokenLength=2)\nremoval = StopWordsRemover(inputCol=\"tokenized_text\", outputCol=\"text_filtered\")\ncv = CountVectorizer(inputCol='text_filtered', outputCol = 'desc_count', vocabSize = 50000, minDF = 3)\nidf = IDF(inputCol = \"desc_count\", outputCol = \"desc_features\")\nlda = LDA(k = 500, featuresCol = 'desc_features', maxIter = 600)\n\nstages = [regex_tokenizer, removal, cv, idf, lda]\n\npipeline = Pipeline(stages=stages)\nldaModel = pipeline.fit(text_df)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["ldf_df = ldaModel.transform(train)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["def cosine_similarity(vec1, vec2):\n  dotprod = vec1.dot(vec2)\n  norm1 = float(numpy.sqrt(vec1.dot(vec1)))\n  norm2 = float(numpy.sqrt(vec2.dot(vec2)))\n  if norm1 == 0 or norm2 == 0:\n    return 0.0\n  else:\n    a = dotprod/(norm1*norm2)\n    return a.item()\ncosine_similarity = udf(cosine_similarity, FloatType())\n\ndef hellinger_distance(vec1, vec2):\n  if (numpy.count_nonzero(vec1) == 0) or (numpy.count_nonzero(vec2) == 0):\n    return 0.0\n  else:\n    _SQRT2 = numpy.sqrt(2)\n    temp = 1 - numpy.sqrt(numpy.sum((numpy.sqrt(vec1) - numpy.sqrt(vec2)) ** 2)) / _SQRT2\n    return temp.item() # to change it from a numpy float to an ordinary float\nhellinger_distance = udf(hellinger_distance, FloatType())"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["temps_ds = ldf_df.select(\n    'Id',\n    cosine_similarity(col('job_topics'),col('cand_topics')).alias('lda_cosine_similarity'),\n    hellinger_distance(col('job_topics'),col('cand_topics')).alias('lda_hellinger_distance')\n  )"],"metadata":{},"outputs":[],"execution_count":10}],"metadata":{"name":"07b.textual-word-embedding","notebookId":1004046},"nbformat":4,"nbformat_minor":0}
